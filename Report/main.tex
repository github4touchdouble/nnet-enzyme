\documentclass{bioinfo}
\copyrightyear{2015} \pubyear{2015}
\usepackage{lipsum}

\access{Advance Access Publication Date: Day Month Year}
\appnotes{Manuscript Category}

\begin{document}
\firstpage{1}

\subtitle{Subject Section}

\title[References]{This is a title}
\author[Sample \textit{et~al}.]{Corresponding Author\,$^{\text{\sfb 1,}*}$, Co-Author\,$^{\text{\sfb 2}}$ and Co-Author\,$^{\text{\sfb 2,}*}$}
\address{$^{\text{\sf 1}}$Department, Institution, City, Post Code, Country and \\
$^{\text{\sf 2}}$Department, Institution, City, Post Code,
Country.}

\corresp{$^\ast$To whom correspondence should be addressed.}

\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\abstract{\textbf{Motivation:} \\
	\textbf{Results:}\\
\textbf{Availability:} \\
\textbf{Contact:} \href{name@bio.com}{name@bio.com}\\
\textbf{Supplementary information:} Supplementary data are available at \textit{Bioinformatics}
online.}

\maketitle

\section{Abstract}

The accurate prediction of enzyme commission numbers (EC numbers) is not only crucial for 
the classification and understanding of newly discovered enzymes but also for completing the annotation of already known enzymes.
Therefore, developing a reliable method for predicting EC numbers is of great importance.

However, due to insufficient data, enzyme function prediction using machine learning is an ongoing challenge.
In this paper, we propose several methods for predicting enzymes in three different problem categories (Table~\ref{Tab:01}).
Throughout the developing of our models, we used a variety of different input features and machine learning algorithms, of which the best will be thoroughly reviewed in this paper.
\begin{center}
\begin{table}[!htbp]
\processtable{Description of subproblem categories\label{Tab:01}} {\begin{tabular}{@{}llll@{}}\toprule 
		Level & Description & Best performing method & F1 score\\\midrule
		0 & Binary classification & Random Forest & score\\
		1 & Main class classification & Feedforward neuronal network & score \\
		2 & Subclass classification & Feedforward neuronal network & score \\\botrule
\end{tabular}}{}
\end{table}
\end{center}




\section{Introduction}

\lipsum[1]
%\enlargethispage{12pt}

\section{Approach}
\lipsum[1]

\begin{methods}
\section{Methods}
\lipsum[1]



\end{methods}

%\centerline{\includegraphics{fig01.eps}}

%\begin{figure}[!tpb]%figure2
%%\centerline{\includegraphics{fig02.eps}}
%\caption{Caption, caption.}\label{fig:02}
%\end{figure}
\section{Discussion}
\lipsum[1]

\section{Conclusion}
\lipsum[1]

\section{Supplementary Information}
\lipsum[1]

\subsection{K-nearest neighbors algorithm using ncd vectors}
A less popular approach of transforming string like input features into numerical values is the normalized compression distance (ncd) algorithm. 
The ncd algorithm is based on the idea that the similarity of two strings can be measured by the amount of information needed to describe one string given the other string. The ncd of two strings $x$ and $y$ is defined as follows:
\begin{equation}
	\text{ncd}(x,y) = \frac{C(xy)-\min(C(x),C(y))}{\max(C(x),C(y))}
\end{equation}
where $C(x)$ is the length of the compressed string $x$  and $C(xy)$ is the length of the concatenated string $xy$. 

We implemented this algorithm in python using \textit{gzip}, which is a loss less compression algorithm based on a combination of LZ77 and Huffman encoding. \cite{Rigler2007} 

The ncd algorithm was used to transform the amino acid sequences into numerical vectors by comparing each sequence to all other sequences in the training dataset.
This resulted in a $n$-dimensional numerical vector for each sequence, where $n$ is the amount of sequences in the training dataset where each
position in the vector represents the ncd of the sequence to the corresponding sequence in the training dataset.
These vectors were then used as input for the k-nearest neighbors algorithm.
Due to the exponential computational complexity of the ncd algorithm, we had to under sample the non enzyme dataset to match the amount of samples in our enzyme dataset, meaning
the positiv in the train dataset were balanced. 

When inferring unseen data, the ncd input vector was calculated by comparing it to all sequences in the training data set, thus also resulting in a $n$-dimensional numerical vector.
This means that the performance on new data is largely dependent on the training data set.

The performance of the k-nearest neighbors algorithm using ncd vectors compared to a random baseline is shown in figure \ref{fig:01}.
Although the mean F1 score of the k-nearest neighbors algorithm using ncd vectors lies at $0.728$, it did not perform better than the random baseline, which had a F1 score of $0.843$.
This indicates that the ncd approach has a worse precision and recall than the random baseline.
At the same time both classifiers have a low MCC 
score of $0.2$ and $0.01$ respectively, which indicates that both classifiers are not better than random guessing.

\begin{figure}[!thbp]
\includegraphics[width=0.5\textwidth]{assets/gzip_new.png}
\caption{Performance on test dataset compared to random baseline}\label{fig:01}
\end{figure}

The reason for the poor performance of the k-nearest neighbors algorithm using ncd vectors is
most likely due to the ncd algorithm not being suited for protein sequences as shown in \cite{GzipProteinCompression} as well as
the test dataset not being balanced, while the training dataset was.




\bibliographystyle{natbib} 
\bibliography{document}

\end{document}
