\documentclass{bioinfo}
\copyrightyear{2015} \pubyear{2015}
\usepackage{lipsum}

\access{Advance Access Publication Date: Day Month Year}
\appnotes{Manuscript Category}

\begin{document}
\firstpage{1}

\subtitle{Subject Section}

\title[short Title]{This is a title}
\author[Sample \textit{et~al}.]{Corresponding Author\,$^{\text{\sfb 1,}*}$, Co-Author\,$^{\text{\sfb 2}}$ and Co-Author\,$^{\text{\sfb 2,}*}$}
\address{$^{\text{\sf 1}}$Department, Institution, City, Post Code, Country and \\
$^{\text{\sf 2}}$Department, Institution, City, Post Code,
Country.}

\corresp{$^\ast$To whom correspondence should be addressed.}

\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\abstract{\textbf{Motivation:} \\
	\textbf{Results:}\\
\textbf{Availability:} \\
\textbf{Contact:} \href{name@bio.com}{name@bio.com}\\
\textbf{Supplementary information:} Supplementary data are available at \textit{Bioinformatics}
online.}

\maketitle

\section{Abstract}

The accurate prediction of enzyme commission numbers (EC numbers) is not only crucial for 
the classification and understanding of newly discovered enzymes but also for completing the annotation of already known enzymes.
Therefore, developing a reliable method for predicting EC numbers is of great importance.

However, due to insufficient data, enzyme function prediction using machine learning is an ongoing challenge.
In this paper, we propose several methods for predicting enzymes in three different problem categories (Table~\ref{Tab:01}).
Throughout the developing of our models, we used a variety of different input features and machine learning algorithms, of which the best will be thoroughly reviewed in this paper.
\begin{center}
\begin{table}[!htbp]
\processtable{Description of subproblem categories\label{Tab:01}} {\begin{tabular}{@{}llll@{}}\toprule 
		Level & Description & Best performing method & F1 score\\\midrule
		0 & Binary classification & Random Forest & score\\
		1 & Main class classification & Feedforward neuronal network & score \\
		2 & Subclass classification & Feedforward neuronal network & score \\\botrule
\end{tabular}}{}
\end{table}
\end{center}




\section{Introduction}

\lipsum[1]
%\enlargethispage{12pt}

\section{Approach}
\lipsum[1]

\begin{methods}
\section{Methods}
\lipsum[1]



\end{methods}

%\centerline{\includegraphics{fig01.eps}}

%\begin{figure}[!tpb]%figure2
%%\centerline{\includegraphics{fig02.eps}}
%\caption{Caption, caption.}\label{fig:02}
%\end{figure}
\section{Discussion}
\lipsum[1]

\section{Conclusion}
\lipsum[1]

\section{Supplementary Information}
\lipsum[1]

\subsection{K-nearest neighbors algorithm using ncd vectors}
An less popular approach of transforming string like input features into numerical values is the normalized compression distance (ncd) algorithm. 
The ncd algorithm is based on the idea that the similarity of two strings can be measured by the amount of information needed to describe one string given the other string. The ncd of two strings $x$ and $y$ is defined as follows:
\begin{equation}
	\text{ncd}(x,y) = \frac{C(xy)-\min(C(x),C(y))}{\max(C(x),C(y))}
\end{equation}
where $C(x)$ is the length of the compressed string $x$  and $C(xy)$ is the length of the concatenated string $xy$. 

We implemented this algorithm in python and used it to transform $n$ input sequences into $n$-dimensinal numerical vectors by 
calculating the ncd of each sequence with every other sequence. These vectors were then used as input for the  k-nearest neighbors algorithm.
The results of this approach are shown in figure \ref{fig:01}. 
The model outperformed the baseline model on the validation set with a F1 score of $0.73$ TODO: Redo gzip knn and make a plot where we can see performance on validation set and test set
the performance on the test dataset is significantly worse. This has two reasons. First, as TODO: find source on gzip algorithm
shows, the ncd algorithm is not suited for biological sequences. Second, the test dataset is highly imbalanced, which makes it hard to beat the baseline model, 
since the baseline model predicts the labels based on the lable distribution of the training dataset, which was also highly imbalanced.
TODO: Yet it is interesting to see that the ncd algorithm is able to achieve a comparable performance on the validation dataset, which is balanced,

\begin{figure}[!thbp]
\includegraphics[width=0.5\textwidth]{~/Desktop/Dataset/plots/gzip_res/test_perf.png}
\caption{Performance on test dataset compared to baseline}\label{fig:01}
\end{figure}





\lipsum[1]

\section*{Funding}

This work has been supported by the... Text Text  Text Text.

k
asldjalskjd
asdjaskldjas
daklsjdalksjd

\end{document}
